{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import numpy as np\n",
    "import os\n",
    "from anode.conv_models import ConvODENet\n",
    "from anode.discrete_models import ResNet\n",
    "from anode.training import Trainer\n",
    "from experiments.dataloaders import cifar10\n",
    "from viz.plots import histories_plt\n",
    "\n",
    "classes = ('plane','car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "data_loader, test_loader = cifar10(256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJztfVuMZdlZ3rf2Pve6V1f1vadn7BmDBwcwcsAIFEUmCEMQ5oE4JoRMFEvzQhSIkBIbPxBLeYAkghCJEI3AYUgQtmNIPEJAQiYmVqJgGAO+jGfGM9PT1+nqquq6nfs5e5+Vh/X/e327zj7V1V09XV3l9UmtOr32PmuvtfY6e//X7zfWWgQEBAQEHH1Ehz2AgICAgID7g/BADwgICDgmCA/0gICAgGOC8EAPCAgIOCYID/SAgICAY4LwQA8ICAg4JggP9ICAgIBjggM90I0x7zfGvGKMec0Y85H7NaiAgICAgLuHudfEImNMDODrAL4fwHUAfw7gx621X7t/wwsICAgI2C9KB/judwJ4zVp7CQCMMZ8E8AEAEx/ojUbDzs/PH+CSAQEBAd94uHnz5rq1dvlO5x3kgX4OwDX6/3UA37XXF+bn5/H0008f4JIBAQEB33j4+Mc/fmU/573lTlFjzNPGmBeMMS90Op23+nIBAQEB37A4yAP9BoAL9P/z0paDtfYZa+17rLXvaTQaB7hcQEBAQMBeOMgD/c8BPGGMecwYUwHwIQDP3Z9hBQQEBATcLe7Zhm6tTYwx/xjAfwcQA/iEtfbFu+3nO37gWwEAndYwa+s1UwBAVPYRONVaDAAwI/f/JPHn1xoVAECp4t9P3UEfADCyadZWLut0Xb8Gvv9Kue6ORL5tMOwCAGJaplj6sDoQ7j92x2bq3vE7MzXjxivjAYCNnSYAoN3uScsoOxbFo7G2hWnXx/LCXNb2qU/8CRgf/bmPZZ/tyH3XGJO16Wdqyh2fhFwf2cj8Ghn9mP3156eyNs3mdtbW3dwAAPTWb2Vt5djdv37D3YP5U6ezY1Hk7vsbb7xB/br5XbrszYo6zne+4x0AgIWFE9mxxYUFAECp5O+jRnf9q1/8BezGo+980s3T3wIYud+Li77fXjcBAGxvu/kZihjTvVApl7O2/nDg+qX1i2K3Z2NpK1f8GFtNt08a9WrWdvb0KQBAt+/3/81bbk1Hsi5R5H8Ho9S1WbpmKXZrGtPtH8lkBzJG8G+jUpaxxlmb1f1k/SK98crXwfj7f/fv+P8URNPpNVGwD4ui73Rf24LzLN2s7LvSL/dli64px9OiPnZ/j77Lvw07cnvdoGjcrm1kuX/pis7T6//R5z4/1sd+cRCnKKy1fwDgDw7SR0BAQEDA/cGBHuj3A8OhkzTimKSbivtcqlaytmqtBgBoiCTdbXsH66DnJN1K7KWhuOSkp4iNSvIGVEkj8gIHEqvjoD5G7oRhf5C1WRFJY5GsTOTfscPUXbM7IOevSHb9ftc3yXerddd/mvq5xyoFWT8Ola50jPvF3UroheeTDGFVa8hJMm4uSeo0kGHLS+O9tXXXdnsza6tId/XZ2aztqjjLX3rxqwCAv173vpazZ865vkjDeXPlJgCg2drJ2spy3xK5BzyXRKSn2PB2n6ydqFYwKpLKIrO7KTsvpmuqlHz+gnczXbnqNIpe389FJb+o7K5Ziv0Y6/Xa2Dhura4BAIa0ZzLJ3ETj4xbEJF3r8ZymsEuajWieSSIaM/U3EqlTNZci7CU1c1vRndDvjkhSvrM+ubuTgv7l+qN95t9k2k7BbyPXg7RF1JppD/LMiKxfwVT2pGpQPN6DIKT+BwQEBBwThAd6QEBAwDHBoZtc1KtmjXcuzi04lbu15VXT2Wmnol84eR4A8OUvfSk7dmvFqaHzSwtZ28JZ55hMY28u6SZOtS+VxYnqrRpI1HlkWSV0f9VxBQBx5JZspCpTkmTHVHmyqTe5qFM25yyRS1ikub4Ar+Kxc2woa7Pda2Ei7Liqx6q3V6HHnUHZeOy4OjxK/fyQunEM200/tq0tAEBvyznmzNCbhaoVZzKoLXjzykAW/UrHm6Cubmzkrv/1117PjjUa0wCAmdmZrK175RKAvGN8QTKQh0M33p2mH2N9yu2nMjmloj0U+FRMDJWSN/kNEzfe6SlvDrKpa1NnKDseu2Ji2yGH8Okzztn7+ut+fuqoVxNDt0umORkiO+vmpudkPL6tP3Bz1X06GvpjamphU5Ed+wBY3aeZaSnig65fMg+o2XIvM0iapuONRY54NjXIcf1uQr+vsjqYc85I/d3S/t/Vb9GxEY1tVOBs3X2syByZm4L8hlPaY5lDumAcanJRh+nu4/eKIKEHBAQEHBMcuoSuEu8w7VOreysnJK20150D7NLGqwCAW9fezI6lI3f+1pqXhmLj3ua1RR/yVW1Mub8V51hN0nZ2TJ1CpdifD5XC6S2qDkx1FiYDfuvK25lWtRSLQ44knrjsvlsTR28v7WXHrEheo5ikLJFqR6P9vn/VYVUkDfFHkT5EMmaJvtd0knfnll9nSLglEq/1VGVs0zW3bqOKXz8jYYJ9cvRdazntRUM3AWBOwjLrVbcea7dvZ8cuXX1DrkNOPdECUtIe+uI0fXPVOUyXSLJbWHDSe0P6d4PDRAwHrv8GOWfLsmfaLT/us2ectnhbnb9Dcp6LtLVyayVre9e73uXmWffjGO1y4k5NT2fHWk2352Nav4rMocvamkryolmwNJ5Jn2mRJJgLAJTvRmPXVA0yJU1SBdFSvMdCFjlAC6TlIslUf0ss5ZcrFf1CwVx4KhomWPA7yLQpatp1LPcddXaacQ2nyOmbd8COD213/9bQXEZBQg8ICAgIEIQHekBAQMAxweGbXCR+uFIlVV3iaUuR91p2RVVf23FqqLUJnS+qD6lnW6su9nkaU1nb/JRzKGnMsjFe9e1LVmiZYt/1GqyxpYmobHKpUkTni/qckFPKSKw5K1PGxrm/ZepDM/WSnp9fKZK1MeTF3QV7R6doJONglVfUSVGlh5ve1NG+5Bx3ccebpWK5RxE5bI04qqyYzqKyn0tfVORViuNXw9rCgndgqzNvIKaUATlW11ZWAQDLCz77NpHjHCOfDMTJVBGHZm18rVgDtgWx2opUnFkafw34PAleZ13TixcfAQC8+vVXff9ysSE5blstZyY5ccJnm67dchmzmr3Zpxj1nqzbAs19WsxTW9ve5JLFjsvvhh2JqtoXxaazs987/8SxSuelWSYl7WLZM3rNIrCZQvvLORezOG36ks2fx85Z7Y/HpqYh/o2qqSUqMLmMCpyo6jjmtt3WktzvV8dDmcca9JDS/c5i2K2Oa9xEk9IeS+iZdq8IEnpAQEDAMcGhS+iZk4Le/sp5YRP/vnn8bY6j48oV5yRr3yCnUOYEIgdl4iSd9rZ/K9bna3LM9R/R7FVaScjRlr3pyfFTFuec+gUtSRClSEKtUi+RRtnb348jHYlkLJljpdhrCqaiGY++Dw3FM6XJ798iCT13XMOkqAszdG3dNSclDt+47OeiPDY1L3FHyoVD8Z4lXUT522NnmvDYnDvlwxbfJhI9O9g0k1PplWenfIjimyvX5SQvuZ6bccc3OiSlGrdGF89fdH3MeN4bDR8b3cmZJijL/HIaQKLal5fAOqK91MW5PTPrHZrbokmy6KicLycWF7O2VZvnWqmQ1Kdher2B3wsrkinKknwmXccFHCNFewHj2oZK5trGUn6Rkz2TltPJmk4RRoXZo/64rrmOkXlpNLSY+9AxcWarKg2jdJyjJY7HnxUasMBL5bXcvLMYAGbn3N46sbxEM3P9rq14J3hTnNoqvZvRuJeUM3iZa+heEST0gICAgGOC8EAPCAgIOCY4dJNLv+dUx4RimzUEe0Qx3nOizr7jiccBAJtb3oHX6jrV1xTQhg66vt+kI2YHucCIHBhK/lUUwzsi80cs8dZK7MVOL5Nlz/lx9PsaM03ZoJodK/HoJbL9lKsS+zz0fQytOErTyWYCdrhkZE00DtX2TM/PpXfDmTP6QhoFIlpSB2hM2ZJWVMKcI0z63ZHvdkktPy3Zm3WO/9a+DDuf3XcbdRfrvUROw4vnHTmX7XkTQyLmhhbFq2+K2agOt969tifu0ih/O+vNMMlosgPq5MmTALwJCADKJbcemjsgAwcAtMX0c+rUqexQs+3a2MyjWaPLND/FQMwqVepfzSA9umcDMZPZHKmT+6Px80X5B7lM0VHenMCwGQXvONEYOy+NktQZYrjbhRwd7R5O6Nz15W8sPzA2ETampsfO198VT7kpzueRbHom3Gu13bOiWmEqYA1cYDI296dadd+tT/ngiuXlk2NtSjJYa/i2nczs5v5EzAYYKf0wXbJ01/RjYwgSekBAQMAxwR0ldGPMJwD8MIBVa+27pG0RwKcAPArgMoAPWms3J/WxF/pdzaT0b69YJJPYeMmkLZmLJ0UKWiaHxM4V90Y2BW9YDQ0EANt3r8OqOEdHTNgvGZophQ5p+FpE4YImjfWg64MkpeEgkUPjYWOsPRijTl83nkbdSx6xhhKSZFyBOmwLuDF0/LksvnES/1SkzcEVXxRisOIqBkZS1KMsEjIARLW6jIOlcaEMJnrg/raTfzdFep9b8sUpSqI5jajIQ5Q5HHMpq/JnnBMl1u+SszWSUoaLFM43d+4sAB9uGd1ez44p50tvmvhgkskS+lC0qpNLfo+9efOq+17Xh3GWhcpZszdZC2vUnaS2IVw3AGAwHsJal7mo5MhSs36an/fz3M7Cdv15WchjOp4pqlJ+TCGKmeOR+vB7S2/GuESfc7BGY6eNIReNqHsxFxo4LqWWxPFekzU1lCG8IJoTQ+8tD2379csAgFuSwTtN912fMwPSdss1d806aUe65trvtevXs2OVmrtnJdI8e0Lh3Wn7/aGh2Kp5DsiRPczGPb4eB8F+JPTfBPD+XW0fAfC8tfYJAM/L/wMCAgICDhF3lNCttZ83xjy6q/kDAP6mfH4WwJ8A+Of3MoBGw4W0GXiJadhyIXNtKmJx5eplAEBTbKPttg9ZU2mP7XRFbHqDrnsrVpryRp7xEuncvBvHiKRaLWyxTVJWt+PGqTbMSoX6mHFSWYve0ttiN21M+cQpZbZT8Yal/CR1Y+QQpsgKI98eb3CTkkQl0seg5W3Mw8uOoXC46SXXWKRvI9rAkDSWQd9JHMmGn0uqZc+6fu0TWaNoxkk0vXWvqK0JK+Lyd32vv+YJkXpJEs2K7hWEsGYiUlHiFOe5iDRUkRJtduD5cRLZK90bl7K2zWSyP0ITgGamPZeLhhqubvj1a3XdNU6IhjVHNtWqrGm55EvtNSTckhNSzp53fDAvvvSSGyP5ClRiO7Hgwxx7ck2VKgFgIPcgLYkGSpKm2nYtaQ+azMJ+l8y+m9ER0nqrCE3n++S8yevIIXmm4D7qV3lXqwTdF4l3mrQT1WZ6tEalsrCTkhY4I2GFGxuOd2eLeIPUJt5oeA24J76HM+fOZ21LJ9yaa3LXY9S/zos1cZXMOZy0IeM998gFOd+v36oUadnZ8vxTtoh76S5xrzb0U9bam/J5BcCpvU4OCAgICHjrcWCnqHXi0sTXtDHmaWPMC8aYFzhqICAgICDg/uJewxZvGWPOWGtvGmPOAFiddKK19hkAzwDA2bNnxx78SiWrXByApyHtUh3JmxKW1hanVLfvVeosE4s1dTNOTN/vSt3Lm+5aUxUfxvZNjzhq04icMLdvu8ILb772p1mbVmJXdfj0aa+WP/nkX3P9U0jcjVvO8bi5s+HHMXQvtrIWJMiF0Em9UwoH0zDBcjz5dg0p7HN422Wr9V9/zZ8ga1miLE+jPBjiiFon/pib226efcrQ7Mg9qg18qGZD1rwramid3u2zt52papZU3oqYXHKZrepgzrIwx80xebIOPW3cgTiSsLGtCnGAyNZKNki93SOKTlX6ZtOblpZPOdX/VJnuS1yXvty4O21P96xZiieWvMmgJQLN+ppfj4sXHwUAnD7plNzb696ko/S9JTJdzIqDr0qcQ7dW3G/j9GkJp6PQucuXL4/NT0MSI/h+1RygIbe5MMeCbFM9vCfhK92zuMCcoP0ytfS6OLPV7LVEmbkaxTygzFnNaOVwUg1xfvLJb5K+vNlwSwqx5Gr8ymTalHk8N+dMsGrKWVz03EOaLdyh8zstpTqm4A75bkeeO3Nz/nkzLea3VpNNxwfHvUrozwF4Sj4/BeCz92EsAQEBAQEHwH7CFn8HzgG6ZIy5DuDnAfwCgE8bYz4M4AqAD97rAPqJe0OV6C2tPB+5ZJySewNrKNCAigmYSMOqxsMWWYpTJrSMKdF6abUaO6nm9oZ36r3yVSfhdne8NjDKhEh3rfUVL1FtrjmJ9G2S/AQAC/POuXJJOGgA4PrNa24ukkhgIz/PqhSIiOl9rQ6lcnlyEkfrDS+Nj264/kfkGCyLtGcpfC3jZlFHFCVb1M45CaUSkxNLHHLRba9tQCSdJHYSY48llKrwnzDviP5lLhdxPHUkNCwlrQBlZdPjpIx4bC7KqZOKBtKmsMS05yS0Gy2/Z4DJazklzs0ahXFui5ahjjkAqMrxYd/t4VbT753YqPbjz29IYYtq2fe7Js6xcxKOOyKJVB2aXGpPHeoNkkinxXmrUuQ67WH9LZU4qUUcnux4V0e050ZhJkY9RsluohFyOORucB+FUr4cZ237prBPanJXRPupLZL26qo3CKi0vrTkk7WmE7e+83Oubf68D6U9fcr9Hrd3vLamIZLlin8e7A5cGLIFQX5XW7fX/Dh67ndQqVLor8xve9tJ71MUPqnaS4UTyQ5e32JfUS4/PuHQ9x388gEBAQEB9wshUzQgICDgmODQuVyi0njNPnVScBaaql4lKaDAdRlT61TSdter6lbeVVMNn4WZDpWbxalPgyFlbglF7Rtv+EzKa9ckO4yJ542qXsIVQ6rY9o4zuTBpvTq0Ti54te/GNadWlqckJnaaiPLlFcsOEtVcoz24HtrX/Liz+qh14prQOFrK/FRn6FCuNiJHW11qW/IalWVeETlx9R5ltMOkN2ossU3Z1CHn0xo1O86c0b3szFK2RbS4Gh7N5rSyZPqyOKK0r0K9W13wlL3dvsQIg4pH9LiGbR4lWauNDW9aWjopdUnJ5LK56dT2UeLU7Yhj62WfNLe8+aMhsfqnl/1e2Bm5XIG+UPE+/tjbsmMrq26f9GmsczPuvkxPedU+Gbq5bm9vyri9GVBpoTlOW+uYWrqPpZI66JX/hM0lYh6g/aE1TgaDyeuYo0gWExjzmah55zblLszOuTVaEL4b5hJaPuXWbWl5eayPRsOvx+bWuvx1929k/TjUnLa85LNOda48Z/1OLM8iNaEBQFOyo3s9KmYhcfk1qkOr8fADzSAnM6BmF5+VDGcA6NC+v1cECT0gICDgmODQJXTl7RiBmA+nRPqm0LNRWaRDETRqxNY3M+Xe5j0Kp1M2v6Vl/wZcX3Nv7Js3XVgfZ2h2u1KNnjhAlH2Qy92lo3xoHbPN6RuY38SZeE0y91DCAwfC+rh8wkuTyWi8vFoWQrZHXNMKqTOpnFjmsD7Jou33qKyaMPfFlfHycbE4MocpOemkjylat52Ok76HIv2Wpr1WEOk6FHDQcOjZtmTLReKUjee8VmW0+judr0VAUnKmpRL+pVLOgKTJkThA6+TkjOPJcYu3RcJlqU+zKq9e9ZoQRm7dBqIBzDV8NrA6wDq3vdTVHbh5Djp+LmeXJcO2JyGN697RVhc+Hc1uBIBzZ5yUurLyZtaWDN06tMRxG5GWpKGxDZq7Oqnr1C9kH7cl9JIDEjSDt0QhvbOzThLd3JzMicNlJdXBzJxGXurlgAhh3hRNq0H7SUM1p6a8FMxhgoqTEgLa67q5dLo+RLEpYce1mu9XQx4Ten505TuVsrtXTQq9nZ11v9ezFy5kbfocY0dzVaTwbkeyrkkr1fXlsXWp3OO9IkjoAQEBAccE4YEeEBAQcExw6CaXiqr51qvPtTmnbp2+6M9rSAX5ekmoKJtefamLCj436+M8K3XJ7DvzaNY2My1xuuvOEVWteZVQnWodIv1KxOFjKE7cWz8ko47m0pNYVKbJrEvMscaXA0BJVM22qnGJd/JU1AmUcwhLgYE98vKu9/z6KTVnlUxWJckKHSbe1DAl9UJPl4U0imL7E3VoklljJGaPct+fZyVmvDpyqm+l7ddqVuP+hxTDKw65Jq3zphSqKEv8dEzjUOf2iEw/pqR1V4kyWPrtS7GQAZmFahWnXjfIrJeOJqu3Gu8/v+gz+9bWXewzZ23WZU8Oeu5mcdy6Fru4teHnOUjdXLa2fduZ5TmZixDBNT09hhZ0OH3qsaxtKPdjlsxB5diZHFckpn1A97hUdvuuWhl3ip49400GupSX2s6kFMfsqHfzm6UCIWfPOqdiuz15HZkSuya/tTKZ9ZREbGbOmxyV2E5jwjm7kuPa/VzGKYM187QhGbNVorlVUwqbEpstLQxCORSSV7EpxHzXr13Njr373e+Wfv1vWp2+7Ai+ctXlg2jG8fnznvxLcy/UBATcH+k6SOgBAQEBxwSHLqFXRYLIVaiSz4vLRJ2pEm5PHJUD/3ZUbgpORitJaFu57N/OFy44kX9z00mCc/P+7V8Th8sjF/xbVNNCez3i9JCMtGpFHCnk6JiWkCim0KzWZZy5jFX3dlaK2pgy8JTDJVflbR+8GQ3i71ApuFYjyk/59lTZr9uy8EksiZMpobCpwZZzzvW4TST0mELVYqWylblUEy+xzYmk2OU+JMt0g8rHrUu4nZV+R31ybuusU3a+ufNsAZeLUgyfqHhJcGHR8cfELS8NNVuTJUtde6VUBoB05CTnpUVPZbu13pJrurHVG36vVarupxWXubCEQ0Q/uyxbV6rR18jhNxSp78UXv5q1nV1y1z972mt1kPDDJ97mJHku3rC148ZYpbBFzTKtlP04+tKHSreseWpoINO/aijeoD/ZKdon7U4dlMytpKHI7CjVkNFUxkPM1ZmWydwvUcaHRFqJhBBGWTgiOXNn3D3dpHDStTWnfTVJO9KiGDVxHLOzc2tzK9e/68M50jmkUum/b62639IC0SA3NBCBVtra8eCBu0WQ0AMCAgKOCcIDPSAgIOCY4NBNLv2OU5/LpJoqfW5CqlVFVLGqqNKmQSYMceBxPcYoq/TtVRrNdHvyyW8BkFdxVGV74vG3Z20nFpxJZn1txbcJAVJFsxVJ1dNPCREspWJ2YJOSXrcijp8KmQeMOkApM1Lj4Fnt241yzfdhB27OUxVvAlgUNXuZqurMynpozPmg61XOklC91ihTVFXMAa3plGQxShIuSrSmJXFYNYkIqSPEYZtEE6vmD+03oXjnzKrCdMLxOMWrxomXZS1niNAK4ii1dF9MMlm9rYqpapXu+/S0M1UNydxUkszdpSW3J4apjyl+8aUvAwB6A7YDTu2aFPDmLRdPPhqJk6zlzRSREnzRuNd1L1BuRFvuW02cqO+gPfyXX/oKgHwWolLD9igGeuXWulxTsobZfinLzKbEa9ccLfRwj9qsbE4YaVUx6lcdmpynoL99tTO2adzqZL1N5HAak851Q9XUoZWceC7b285ckpDj/eJFZ4qdnaZYfXH2t/quLybLW11x+4KdtFvbbo+n9EOfm3Um40rZmXfW1/yeP7PsycQURVXW7hZBQg8ICAg4Jjh0Cb3XcVLCiMKqUpG0NVMOABJxwlQknIhrefZF2hr2OaPTfR6BJF2REhoipSrlJeDf2OxwmZt1542GlLkIzQZVSYoy1eQFOyKJQ7leOORwWmqPRlFD5uml5kGqIVRcrUP4OGiNdoMdSyq51khjmdMaqFSnNVl1kkZPJOiEnIapSOYsyXYlLI8zbNUhl1Sd1Jewo7Lt+uMQsZ0dkVYoI1clqrQgo1QlOnamVWOppk6he4lmwso+adNctloilVGo5OwetK+675i7ZFoqvTNt7aDk9ky96vpaoozfpmT9bbW9JHj9ppt7d+D36fyC0OaKxN0fEg+LyFstyiBsdd06rFKxDpWcKxIeuvPyy9mx2+J8pmg6lGR/NM75ypGqAfeUm4ipb2UvlinMNxGHZxEtbva90fixHP2OSrN0mv7+9PcSUfik8ruwptqRtRmSxK3cNy9Jndac5i5zP3vaz12zaVk+rlT1dy21U4nDRwMhWDtflsItI4pm6KjjXX4vnImqhXJi0jKLwjLvFkFCDwgICDgm2E+BiwsAfguuELQF8Iy19leMMYsAPgXgUQCXAXzQWrs5qZ9J0BCuIb29lMckjoiToiySmkjcMQ9dTkuGZFdsOlL5wYKXwj1TnthqyTY5SvIcLQAwVNs8v/2loMNA+Fg4UacuCVHTMySpSdjYG1cvZ21KeH9S7GgVCiVMRpqgQNqGSLh7hS0mZMtUO+h210t2ysR3kiSIZSXoH0hIGXdYc/8zLI2LxMFskpGw9FVl7kyRuSWSEley35JwMS4L1uvtlvY4lEtLCRIHiEpxJHmpQtMXja9LbJxtkYb6JLWXzWRZpiIhslwUoiuS9rBL6yx/G6I1Li8sZcdOLjsJcG3Tx931Ou67tympaWNT9qnwsTCz4lA+MzdQS7Yz5Wpla5OUJJRw5Pe8VpI34N+ShAaSRqTV7dVXYWl9RnDnlUljmaprUtXkOsGjnB9ofPfq75yr02XnZaGSzH/i5nfihA//0+92SPNcFN/XxUdcCDJr+vPz83Jt2jtFg7f5D5Y0/VhCTJnBMjud1k3H3u+6Z0CjRslappH/Hqjc4gGwHwk9AfCz1tonAbwXwE8ZY54E8BEAz1trnwDwvPw/ICAgIOCQcMcHurX2prX2L+RzE8BLAM4B+ACAZ+W0ZwH86Fs1yICAgICAO+OunKLGmEcBvBvAFwCcstbelEMrcCaZu0ZFuFk6Xa+aliSEMYqJ6lXrb0q2orVElB+Nm1BaEp7UIzV7JAUGYuHqYFpcDUfLOSNFIZohE8pAvttMnFOqR9lwnY4W0PBqcypVGG7cuOHHIarYvNBwqtMT8I6RDnGzaP3NqIAqVNEmTghVMZsd38eOhCEaUhMXxamjV48ofDKqiNmLVVOJTbRkcrFikmmLaYlAeVXmAAAaqklEQVTjM2tiKrqx6cPMVpvlsT7U4anqNvNhqOOM74uaB5Lb3sKnGaLK79La8Q7QSNZ3QPeqHE0OEUsSO3Z+SRxn0xT2Ob/g9tMjZ9zWT2hPvvqyq/H6ptTIBIDtpphVqN5HR0wWJlJTIjm3vR5PY5N6uyO/x6YkXFFvlQYaAICVrNEBmW0aUiRjdsFXsr901YVPVmvOdMbqv/aRUrbugmREtttNTISZvMbusMn9pSlkbex4vPT662N9TEu2syGTjgY4nD7l+Gbyo9Aw4nEDBzslze7wzVy9YjmWjvfBpiXtY3FR6vOWmR9Hz2ez1Fh3d419O0WNMdMAfhfAz1hrd/iYdbMoHI4x5mljzAvGmBc6ncn2toCAgICAg2FfEroxpgz3MP9ta+3vSfMtY8wZa+1NY8wZAKtF37XWPgPgGQA4e/bs2EO/LOyCM1M+MSCVJIuI3xEjLTYhIUD0dqxLqbVhw0voyprIPCxe2huXdDVMqlwhng0JXUpTCqkUSaosTtR54u8YivNoe8dLpDOzZwD4JBTAs+FlnBNU3iqO9DNzXri2tECqUCRtH8bWGzoJzaYk2cl6pSNKXBEptXLaFU0wJMX1pCzcKo1jO6v+7tfvgkg8JdFcDA0xFsduj4pqdIXx8NS8v99G+G4G4uljB6hKPMxyqOJNi7QvdZA2pAQYM/3tSFgmh8D1SZvbDWXnG5GmUBbpytI4drpuLa/ccFu/3/cCS1Mk160ddv5KiCfXPzEaACBJRDQOldC5PKPymaQkzmmoazmR8+i3oXvekvQ5lI+Xrl/z85N7oL8DDoONxNG9SSX5WhIKyoVHdiMnGasWxntYr5H3iubO47A+/11aD+0j96gY30f+2Gjy2ApEZG1jiT4q0Dx0vfLahvvuonC45PpX3y/Gzz8I7iihGzfC3wDwkrX2l+jQcwCeks9PAfjsgUcTEBAQEHDP2I+E/j0AfhLAV4wxfyVtPwfgFwB82hjzYQBXAHzwrRliQEBAQMB+cMcHurX2/2ByNcvvO+gAjJgpqhTjqiHhnPlZFdNMtSzZmymR0UvBgyrFHvck9pMzyDRWu2ylL8r6y9Qd0lm06ABnP0ILBohDkx0pWm+0teXNH6W2U02N9eNIpV+N57Yjv7yNujNFdAfesTUYTq6snn2v5NdKzQ+JJfORxM7GFO8fCWdK5aKrNN+/eT07dlW4Vl4js81I7seIHJQLct9Oi0aaUhbfoOrMH1RGBLNyvEyZmkbMXFNCAcz8IN5pRDVZh1q1nkwisgemp6XW5YZ3mKqDmU1FlT3i0OtitqGQeqIwJuebrHOz6+5PQsHhI/lpTU97CugolqxoMrloMRI1E9iC2G3m+tF7m6tzK+vVETOSTdh5KbHx9NvYaLr9aaiPktxHg3FzpJqqEsr47Q9kTffw5PFvIzNdmHETCvegpgt1RrIJb2lpCbvBuSdZH/4Krq+CseUyq/WvGb/hpiBTOftuzgE61pSZUzIzzx2cxNEee3K/CJmiAQEBAccEh87lMiO8JspuBhDJPkmCpUhLaUm2Z+SHriW1SiTl62s3Sbxk3JbMyapwkrCTLBLJsZ9QKTeRjJmbpSSSoGoFjKo4TCnBFZ2WsLUZL0mMZExbkr3Z3PFBQyennBRSq3Ghg8mOJ0VMa6WjnSIRsyHS+AxJWVl1eBnHoO3nfnng5rJJEnpDmSAp5PCqSowiXRgqyzVYFkcbsfRNqSOWxq6aysgM5f9U4EL671AoXlck4hz3i0i23Y7TzLZJS0ol7K5E5c8axM2xGxVxiuaLjEjm4oi1B3GkRyLdkiNWJe+I9qlmBA+pFN4oC1nVTOjxDM28giwcJ9RUEu2rKgNuzHnuoROnXDZym7SZbiqFVSIqEiPaSyx/WVpUCZN/o1FJtJgC/p1spMysWCTJF0msVuc3fkylcT4SZVnDe+RZ0rU19LdIe8gVTNklmccF0nvR+DmjdHdYJq9p5ny+DwyLjCChBwQEBBwThAd6QEBAwDHBoZtcpmekriepTInEtkakV2YxpaISlqr+XZSIg7RW8mp0LDHelRI5W8V04eOLyUxhleaWyJfEhMLJo1kdQaPOGz9uNQFUp7zKG4lpZp7U4O0tZxbY2HaOx9WVN7NjiwuSVcZFL7LiAJPV23ZCsexS2ELJwgAgljlwcYoVcc5WhbB/o+3NGlvqqCU1sSsLUaFY7DW5b1pgw8TjjticI1GKMfRIlhgICVUWRk1x1P2eG2OP0it1Bhzbb8V0oVXd2cneEuKm00SZOivO05tUxEJRkphz3n8lLbphfb8+3lmPsdo/Htus3eXNJZF2Jn35g6rm5+KT5ctlMqedkgIby0JaNTPr7/vqlosdH/R8PPzMdE26olwHmYNSzbIhoC81XuMSORJlymxS2gvan2Xn4h5OQlPgZWSytLHzaU/qN4roaIuyU302KHs088RhOadogZlE71HMhVjUDJl1Qt0X7I+98kz2iyChBwQEBBwTHLqErs5OdkCVpY0l0oxbQZosve6qQrxvrHdUVoUClSVdlagGwttSolJnev0R85RIzJSN2eGoDi2RaMgJok4szuKLpfr7mUfOZW0bWy6LcHPbSeqvX3otO1YXZ93FdzyatZXFmTZIvAS9GwunHvHjEEmxRyGKug4VqiofydiUlP/WGz5zMBKn6Le+851Z2/q6K5Zw49oVupa7Dz3Rfqpc5V6OjUjCjMX5HBNlcEnC7PoiSd/e8Lw+Qy0QQmtalj5GIxZ5VOJx49YiIoAPg2x3fNawho4WIRapOSehZ456f57uRe0/Im94QzKIDe2PrS03vxHva+QzIlka10+WNJZU5lejay1MOSf/VMPd4xJ7nMUZr8cAn0hqScrP1tSOc52YSIo80I80STREcrJUyaGBqoHknJEFEmnG66Pn0DG9H4VFNXIStM01cfCDNpaI0yjTHnjOWUa6au4YO3/XAGRsvkULu6gzN6Fny1B4kZptorje2YMXZ58IEnpAQEDAMUF4oAcEBAQcExy6yUUdlRznqY6iNGEnRV4NjgoqvhtySmk9SK4/qN9IMkIhf0yzPAcUh57a8SpGegk1NUQ5Gtbx2NJUzqtM+Uy9s1LLsSv0tjtNH4d++YozZ5y5cDZrq0nGZW8Pk4tWcgeAvpiUWIVU6lNL67F0yo2jLef3yPu7tOToUbUiOgCcOeNIvDY2bmdtnbYbu/qC6g1vSlH1uUIx31lBmgKHVU3yA9bXPQmUOppjcnppbVXOKB203FqqaWlhwWdoatw6VwPiCva7oZaFXL3HzKFJTkuZQ6IOdYpRLwtZ2bDEJgZ3XkJx9lrpPVP7OXZb7xkPTo7PkOns7EkXa27q7t6ubPq6pNW6mEtI3R9Ixi8T3Ck5mJp3DKVo6lx4X5ekShNKkzNFh0Tcle4zW3IvZN/MmVcceN200tlQmjhnRE2160S93Go5U1yZfhs1yUUosq+o2YjzINRx3On4fdWVDOWOmFW6RImtWbcROXqrVFnpXhEk9ICAgIBjgkOX0EdC1J8L2bGazVWm89Q5po42D5WuLWVBakZnverfeqk6tjKKTv+GVYdZs++lZRMX8Dhkn+Uv896LLFWiUC4N62I+mIVFF6o5I86sjS3vGFFHcEoOzeq0k3rj3uTbxc40lSZPLPrai1p+8/a1y1nb7Du+GQDQk9BAlTIA4Nx5J5nfuOH5Xaa1MMLsXNa2I4VEBllGqR9jW8IgS1V/H6enp2U8fL/d4OoioetfHluJHFsnT7rCBa2OX7e1W64+qvq66sRdoo7SQX9cYiyE7jXSWLLypYZD90RyjXS/jmeRsiKSOR7Z8b6rqAfXSc1uac5Z5xpPLNO9lRDeddGchnS+FqfgbjVjNi6xlqsZvxIWWfHrl/pIhAyxUD6nGOdS2T18gPhSuE1/j/wdHUfB+UWZmdnvMaeNSuZxluE6Xpyi3R6v69rucJa4OnEhf8evPSQK5sFAta/xuegYp6b8vl466UJN50mznp12jvyvv/q1sWvtF0FCDwgICDgmeAgkdLGRkuQzENvbkBgHjRYAUJuT4VAu4QAhCSzOhAqSspTdTa5ZjomPRfrr9f01I5FgmNFNCx2URcoZpcw74s5LqWBFuSJvZU44kNf+CSkBttX0hRGGUv0dnERkNdFlcmIFS3aaHDIim67a/FfIPr264qTvayLdNqlgRElsvztU2k7nzILS4glnv52adsksllgUG7NOGudQLpWMuZK9lvHrdqW8IM0rltBS5lBZXXMFJRJmZZRvqW38tVcvZccGcv9ispGWZBL9XoFfQq9F91FZAmPSvnReygNkaIwq3Jep7Fi8RzGG3X0CvsQZ38dZCcc8IeXVAGBb1s/GyphIYZFyTf59abV6Xr+hSLVGtWP2FYgmUmb+IvUlFXAaKXJ8LKXxR03GwJgr/JC3yXMiEgo4V7LhkD1b/UXNptO6+wPmznF/hyS1lySElsv67Qivka69KQihZr+OcsSUKpTgtKs4Rq3uQ0fn5pyW22gwn84DKHAREBAQEHA0EB7oAQEBAccEdzS5GGNqAD4PV6egBOAz1tqfN8Y8BuCTAE4A+CKAn7TW3pnndRf6PcmmGnj1TzWZIZk6tO5m5qgik4s6Eoc9f/n6yKmCXEE+o9TVDC6ihrWipsXkhlGyf872S8VZYiW8kU0HmWMrZSpgd94U1UyFOKpmxSFy/py/plarb3c8/WujOitT3ivki8cdjbWpmWlAppkvfu0VAEBTnEHMobK17a5/4cJ536+YjZQvBQAaEo5pJYO23aaiJJKtO6Jr9rrjhRy25VrK18IUpJpxmeO80HA+6rei3lCZco9CFNXUwo6tKJ5svvKrxzwi6lCnvaDOTTXhkVlhJPe4TBmJmoHKZhbNplWTEZsONKOU69w+9vhjAIB+6te5Lc5szeS0ReYSGocugyFTRE3NMDI2NoOo809rrQKUFb2HbzkpoNa1BeYVU0BlW7TTs2zxogxT7iPVZ4WbU3fgnZ2bm86J32y1+NsAgJhSbGdkX1ckZLNaYce+M3tViSpaTWvVqr9XOv9ux5lU2cTVk5rHfcpe5mvcK/YjofcBvM9a+20Avh3A+40x7wXwiwB+2Vr7OIBNAB8+8GgCAgICAu4Z+ylBZwHoa6Qs/yyA9wH4e9L+LIB/AeDX7nYAAykR19rxjsGZOeHh4ErlIiVoUsaIa1Ops5NKgDWE36U/9NJkKm/i7sBda6fj+9CkHXUKuX4lmQnMoJa/Jp+fRXeRFDcUDWQ49BK3srBNSbGOxx9/e3Zs87ZzWiYk5belgrzZQ6rkcmkqfXKomjo8DTktr4qDNJaQQOb2WF11ySnLJ5eztlbThXoNKGFEkzK2t13oF4cXqlTIBSuUyTCme6vlzFSSr5IjEeU8twf/JxcWlxURGD/fk+kxT8pkbSdLIqK2WKPjSOrMWDDlxqcpx6xlGWhjA88VQVAOkEzUpfBTGcjjT/j9URfJsUlakt3lLI/oHmviUpn3juxdLghTls9NCQUtkRNVoxtZOyllhTYmO/LYKaoSP9/3om9mbIh6DrNVRlHuL+CTdXT/AcB2UxJ6REtjeb7acI76OQlIAICyON5rJHFr6KzuxVqN1qqs3DakFWfjHC+SgUVNcuP1cH9ZK262/DPwXrEvG7oxJpYC0asA/hjA6wC2rC9seB3AuQnffdoY84Ix5oVO5+ADDggICAgoxr4e6Nba1Fr77QDOA/hOAN+83wtYa5+x1r7HWvuevcp+BQQEBAQcDHcVh26t3TLGfA7AdwOYN8aUREo/D+DGvQxAMwYrtSq1OdWEVdih1DNUalrmUUjEuVMilSYRVbBD/CeDRM024gAl1TRVgnqidUWSzzgDkAVhq1rLccmxKCxxLj1QxtElHgdR0atlcRDSXZhfdqrgiGOJswrokz1QTNmrana75bPhbkmsecKFImQuiawzq3/qqPzSX30la+tLvDPzoHhHlfCDRBTzm6qzkGiKM/MH8e5ILPNoV9Yk4PMO8vUetX/fNlZEwBYcy6m8k00uQ+G24bj1rFgH3YKMn0SVejqoPDrdrtdKlbaZ93WWyam1WWncjzx6AQBw6oyPOW93nWmBY5pTcZYrB9IUZ8nKtXKJjnJ+pezP64npsyFmh5yhSE00tK9rcs+KmGwVvH66A3JmGDWV0ney26f/L+BtYehxdvouLri1OatmE3LmKg9QVMDTk8tY1bHZPL2xayyq9aqmovFR2gJzTLYO9Axih+q94o4SujFm2RgzL5/rAL4fwEsAPgfgx+S0pwB89sCjCQgICAi4Z+znlXAGwLPGxaxFAD5trf19Y8zXAHzSGPMvAfwlgN+4lwGodMghQ1oOCzGFiEnmYkWyFXs5KVGqnZNTQwsB9Mi5qITzRtjYopi5YiTMjEuoydt2lFAGqkodZvyNbCRLzOSy8tx46w0ftqjZqBoSNRiNs++xQKAFIvaS0IeU8diRQhEsDSm3TS55T52nmaTpJYhEpMlWLuzTHa9U2PEpGXIihbNTVK/PhUSy4hEF/DgaepbP7nV/mXtF7xWzLXqun3GRkQsL+PMnS+jKAMq1B5OhGbumHs0YE6lLDWnk8fgwPt9WFWfbtJQtbEz7whxvf7sLUbSRH39NpG/mEVHmxYrszQpJfRhJGzma00S1Ys8tUhHtS383HXK6ajhmlaTgSqQFXiajkKOliBepoPRbxr5K5xfd2ykx487MzIwdK2J29BoA8/RoyKifTeaA1VDQgrkwf8xu3hb+zm5HL4N/51OUNXqv2E+Uy5cBvLug/RKcPT0gICAg4CFAyBQNCAgIOCY4dHIuJchia4KqdmnOW6J0pE5HqRIlqxFHR40oPzU2mLPySlL8oFpRkilyjIiKzOaB7FhEdUlFLVNzRY6gJ1ONKYZX5sIk+yUxWUSisEbkPCpnBEt+QfrisCqi8FRo/DrgM2FZ44wi19/cvKfrVKdlkbqYFaegmqxRVleTzxv/rkLV2gjRWFtaQKwFMQWwGp/RJecSDMezMKNIs1KV0IqyPMV0p4U/gF0x47uwte2KH8RkPtLeBmTqMLtivKNczU23tn12Qksvp097J+eMEJjVas50UCLTyMaWu6cVInwych81fwPwu20k96dHc9djnMWqvttm2zts1amue41NXGpGG0RUFESvYe5OJrQFzuqcazEjvlLT5vixInDgQrav9zjf5JycBW0ZK686R8cO5fvT4ACe3x7jzkxQe3mV7wFBQg8ICAg4Jjh0Cf1//+H/PewhHAu8/PKrhz2EY4M/+38vHPYQjgX+86c/c9hD+IZDkNADAgICjgnCAz0gICDgmCA80AMCAgKOCcIDPSAgIOCYwNzvsJk9L2bMGoA2gPUHdtG3Bks42nM46uMHjv4cjvr4gaM/h6M0/ovW2uU7nfRAH+gAYIx5wVr7ngd60fuMoz6Hoz5+4OjP4aiPHzj6czjq4y9CMLkEBAQEHBOEB3pAQEDAMcFhPNCfOYRr3m8c9Tkc9fEDR38OR338wNGfw1Ef/xgeuA09ICAgIOCtQTC5BAQEBBwTPNAHujHm/caYV4wxrxljPvIgr30vMMZcMMZ8zhjzNWPMi8aYn5b2RWPMHxtjXpW/C3fq6zAhRb7/0hjz+/L/x4wxX5D78CljTOVOfRwmjDHzxpjPGGNeNsa8ZIz57iN4D/6p7KGvGmN+xxhTe5jvgzHmE8aYVWPMV6mtcM2Nw7+TeXzZGPMdhzdyjwlz+Neyj75sjPmvWo1Njn1U5vCKMeYHDmfUB8MDe6BLxaNfBfCDAJ4E8OPGmCcf1PXvEQmAn7XWPgngvQB+Ssb8EQDPW2ufAPC8/P9hxk/DlQ1U/CKAX7bWPg5gE8CHD2VU+8evAPgja+03A/g2uLkcmXtgjDkH4J8AeI+19l1wJTY/hIf7PvwmgPfvapu05j8I4An59zSAX3tAY7wTfhPjc/hjAO+y1n4rgK8D+CgAyO/6QwC+Rb7z7+WZdaTwICX07wTwmrX2krV2AOCTAD7wAK9/17DW3rTW/oV8bsI9SM7BjftZOe1ZAD96OCO8M4wx5wH8bQC/Lv83AN4HQKnwHvbxzwH4G5ASh9bagbV2C0foHghKAOrGmBKABoCbeIjvg7X28wA2djVPWvMPAPgt6/CncAXkzzyYkU5G0Rystf9DCtsDwJ/CFbgH3Bw+aa3tW2vfAPAajmBFtgf5QD8H4Br9/7q0HQkYYx6FK8X3BQCnrLU35dAKgFOHNKz94N8C+GfwdSNOANiiTf2w34fHAKwB+I9iNvp1Y8wUjtA9sNbeAPBvAFyFe5BvA/gijtZ9ACav+VH9bf8jAH8on4/qHHIITtF9wBgzDeB3AfyMtXaHj1kXJvRQhgoZY34YwKq19ouHPZYDoATgOwD8mrX23XDUETnzysN8DwBAbM0fgHs5nQUwhXFTwJHCw77md4Ix5mNwJtXfPuyx3E88yAf6DQAX6P/npe2hhjGmDPcw/21r7e9J8y1VKeXv6mGN7w74HgA/Yoy5DGfieh+cPXpeVH/g4b8P1wFct9Z+Qf7/GbgH/FG5BwDwtwC8Ya1ds9YOAfwe3L05SvcBmLzmR+q3bYz5hwB+GMBPWB+3faTmMAkP8oH+5wCeEM9+Bc4B8dwDvP5dQ+zNvwHgJWvtL9Gh5wA8JZ+fAvDZBz22/cBa+1Fr7Xlr7aNw6/2/rLU/AeBzAH5MTntoxw8A1toVANeMMd8kTd8H4Gs4IvdAcBXAe40xDdlTOocjcx8Ek9b8OQD/QKJd3gtgm0wzDxWMMe+HM0H+iLW2Q4eeA/AhY0zVGPMYnIP3zw5jjAeCtfaB/QPwQ3Ce5dcBfOxBXvsex/u9cGrllwH8lfz7ITg79PMAXgXwPwEsHvZY9zGXvwng9+Xz2+A262sA/guA6mGP7w5j/3YAL8h9+G8AFo7aPQDwcQAvA/gqgP8EoPow3wcAvwNn7x/CaUkfnrTmcPWQf1V+11+Bi+Z5WOfwGpytXH/P/4HO/5jM4RUAP3jY47+XfyFTNCAgIOCYIDhFAwICAo4JwgM9ICAg4JggPNADAgICjgnCAz0gICDgmCA80AMCAgKOCcIDPSAgIOCYIDzQAwICAo4JwgM9ICAg4Jjg/wPtPewShg85oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog truck deer plane\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "# functions to show an image\n",
    "img_size = (3, 32, 32)\n",
    "output_dim = 10\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "dataiter_test = iter(data_loader)\n",
    "images_test, labels_test = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4, :,:]))\n",
    "# print labels\n",
    "print(' '.join ('%s' % classes[labels[j]] for j in range(4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0/196\n",
      "Loss: 2.295\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 2.165\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 1.953\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 1.874\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 1.707\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.667\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 1.577\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 1.586\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 1.540\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 1.431\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.589\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 1.325\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 1.355\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 1.326\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 1.328\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.345\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 1.376\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 1.401\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 1.296\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 1.274\n",
      "Epoch 1: 1.554\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.364\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 1.135\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 1.102\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 1.243\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 1.215\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.228\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 1.249\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 1.219\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 1.095\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 1.182\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.218\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 1.110\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 1.121\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 1.084\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 1.161\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.074\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 1.105\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 1.195\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.971\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 1.100\n",
      "Epoch 2: 1.177\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.103\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 1.042\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 1.107\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 1.112\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 1.030\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.884\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 1.075\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 1.072\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 1.014\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 1.079\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.086\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.960\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 1.004\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 1.122\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.976\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.116\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.933\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 1.003\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.972\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.972\n",
      "Epoch 3: 1.029\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.878\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.977\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.981\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.948\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.983\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.984\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 1.154\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.929\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.996\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 1.041\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.850\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 1.002\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 1.064\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.889\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.818\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.062\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.910\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.931\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 1.016\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.875\n",
      "Epoch 4: 0.944\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.864\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.887\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.864\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.851\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.816\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.024\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.950\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.867\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.950\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.765\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.829\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.914\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.814\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.731\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.838\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.728\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.785\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.976\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 1.000\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.748\n",
      "Epoch 5: 0.864\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.717\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.771\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.891\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.710\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.824\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.822\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.880\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.844\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.748\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.808\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.757\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.778\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.766\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.761\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.692\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.727\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.800\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.737\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.669\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.818\n",
      "Epoch 6: 0.801\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.711\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.829\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.716\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.794\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.652\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.675\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.891\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.813\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.791\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.774\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.690\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.709\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.650\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.774\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.810\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.024\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.885\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.835\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.795\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.874\n",
      "Epoch 7: 0.771\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.817\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.642\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.723\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.792\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.759\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.630\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.723\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.683\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.828\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.716\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.727\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.777\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.777\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.686\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.673\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.773\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.868\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.768\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.711\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.722\n",
      "Epoch 8: 0.715\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.633\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.758\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.664\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.753\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.747\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.635\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.713\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.648\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.674\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.724\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.687\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.617\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.604\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.716\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.724\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.802\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.642\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.729\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.712\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.695\n",
      "Epoch 9: 0.695\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.705\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.795\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.609\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.643\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.582\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.688\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.660\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.694\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.638\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.689\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.561\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.665\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.684\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.705\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.743\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.829\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.815\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.685\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.643\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.707\n",
      "Epoch 10: 0.668\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.677\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.555\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.675\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.567\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.573\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.627\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.557\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.633\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.614\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.626\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.517\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.626\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.524\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.528\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.689\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.521\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.665\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.636\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.573\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.728\n",
      "Epoch 11: 0.632\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.577\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.563\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.564\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.707\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.554\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.607\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.657\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.578\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.625\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.507\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.612\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.678\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.505\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.642\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.659\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.619\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.653\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.643\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.797\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.701\n",
      "Epoch 12: 0.605\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.566\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.677\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.667\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.586\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.648\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.521\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.459\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.534\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.576\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.598\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.526\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.555\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.552\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.592\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.615\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.603\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.539\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.634\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.584\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.576\n",
      "Epoch 13: 0.579\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.455\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.619\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.572\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.535\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.599\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.506\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.707\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.506\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.605\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.525\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.480\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.482\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.501\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.512\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.500\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.588\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.454\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.461\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.652\n",
      "Epoch 14: 0.548\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.635\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.598\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.579\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.661\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.571\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.605\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.620\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.612\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.556\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.510\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.506\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.563\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.460\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.606\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.508\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.549\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.527\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.509\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.481\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.495\n",
      "Epoch 15: 0.542\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.572\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.574\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.515\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.570\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.508\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.426\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.484\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.520\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.440\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.439\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.572\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.512\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.619\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.454\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.411\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.601\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.532\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.548\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.510\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.486\n",
      "Epoch 16: 0.509\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.494\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.391\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.485\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.517\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.448\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.510\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.488\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.515\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.464\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.488\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.485\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.449\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.546\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.412\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.434\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.464\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.494\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.446\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.525\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.627\n",
      "Epoch 17: 0.484\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.491\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.408\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.395\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.393\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.457\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.392\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.397\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.456\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.506\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.522\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.434\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.466\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.480\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.469\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.619\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.532\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.573\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.453\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.406\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.502\n",
      "Epoch 18: 0.479\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.438\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.464\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.431\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.519\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.371\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.406\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.431\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.499\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.466\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.447\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.480\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.348\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.467\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.534\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.515\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.577\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.419\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.423\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.681\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.421\n",
      "Epoch 19: 0.460\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.378\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.404\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.487\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.407\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.434\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.356\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.321\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.354\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.420\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.392\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.512\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.403\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.422\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.516\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.475\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.324\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.417\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.453\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.360\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.520\n",
      "Epoch 20: 0.427\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.448\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.343\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.312\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.474\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.429\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.428\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.352\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.422\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.444\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.382\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.363\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.396\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.318\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.409\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.515\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.410\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.459\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.407\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.454\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.362\n",
      "Epoch 21: 0.423\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.396\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.487\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.386\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.296\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.333\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.473\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.511\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.406\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.450\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.426\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.308\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.310\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.399\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.330\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.439\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.388\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.441\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.362\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.409\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.338\n",
      "Epoch 22: 0.398\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.352\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.287\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.428\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.330\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.305\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.368\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.413\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.426\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.385\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.332\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.391\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.342\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.396\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.376\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.405\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.375\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.403\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.357\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.350\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.411\n",
      "Epoch 23: 0.376\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.309\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.384\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.364\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.462\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.312\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.303\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.413\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.362\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.353\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.325\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.385\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.389\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.412\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.315\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.495\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.362\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.321\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.370\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.437\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.585\n",
      "Epoch 24: 0.370\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.319\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.344\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.324\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.319\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.287\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.358\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.302\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.378\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.385\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.346\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.324\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.369\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.366\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.426\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.368\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.307\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.376\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.390\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.327\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.488\n",
      "Epoch 25: 0.344\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.357\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.288\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.232\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.302\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.315\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.313\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.305\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.313\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.294\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.248\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.298\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.332\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.303\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.297\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.335\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.276\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.271\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.312\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.442\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.439\n",
      "Epoch 26: 0.322\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.396\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.287\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.291\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.254\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.262\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.306\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.221\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.301\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.257\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.274\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.325\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.361\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.395\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.333\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.399\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.345\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.293\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.377\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.286\n",
      "Epoch 27: 0.314\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.307\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.353\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.277\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.218\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.288\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.245\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.241\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.233\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.312\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.384\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.229\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.287\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.309\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.268\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.329\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.283\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.325\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.293\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.340\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.323\n",
      "Epoch 28: 0.299\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.234\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.272\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.273\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.255\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.341\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.256\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.236\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.229\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.284\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.272\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.277\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.274\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.272\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.338\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.378\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.395\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.223\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.315\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.289\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.296\n",
      "Epoch 29: 0.280\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.253\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.238\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.357\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.203\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.199\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.240\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.220\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.270\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.225\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.156\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.271\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.344\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.418\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.321\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.314\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.258\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.269\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.259\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.288\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.258\n",
      "Epoch 30: 0.270\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.227\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.243\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.290\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.276\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.289\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.213\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.253\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.270\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.264\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.273\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.314\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.266\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.264\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.335\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.273\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.369\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.290\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.298\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.309\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.237\n",
      "Epoch 31: 0.262\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.289\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.135\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.173\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.244\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.230\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.236\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.193\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.262\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.254\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.274\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.293\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.258\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.329\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.257\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.204\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.322\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.229\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.206\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.329\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.294\n",
      "Epoch 32: 0.246\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.245\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.254\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.195\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.193\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.139\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.242\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.191\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.220\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.154\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.205\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.261\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.290\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.281\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.332\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.231\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.209\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.212\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.236\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.297\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.288\n",
      "Epoch 33: 0.238\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.275\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.229\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.231\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.141\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.171\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.130\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.124\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.197\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.165\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.324\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.284\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.257\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.201\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.196\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.356\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.210\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.240\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.248\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.268\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.203\n",
      "Epoch 34: 0.232\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.229\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.247\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.234\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.162\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.133\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.221\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.135\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.342\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.373\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.244\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.188\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.196\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.187\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.269\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.238\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.221\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.165\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.209\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.251\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.307\n",
      "Epoch 35: 0.218\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.173\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.128\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.224\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.189\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.135\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.168\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.173\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.242\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.125\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.220\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.178\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.182\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.164\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.254\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.235\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.266\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.209\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.176\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.262\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.201\n",
      "Epoch 36: 0.194\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.198\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.146\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.122\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.129\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.187\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.197\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.182\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.158\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.183\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.224\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.258\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.132\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.112\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.169\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.230\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.177\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.171\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.163\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.179\n",
      "Epoch 37: 0.174\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.124\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.292\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.247\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.199\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.252\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.123\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.227\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.251\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.197\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.174\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.115\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.209\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.167\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.166\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.230\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.242\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.185\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.191\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.178\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.204\n",
      "Epoch 38: 0.206\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.163\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.166\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.141\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.150\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.194\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.166\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.110\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.134\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.156\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.184\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.198\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.131\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.131\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.136\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.277\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.233\n",
      "Epoch 39: 0.165\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.150\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.158\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.186\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.105\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.148\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.104\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.111\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.220\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.178\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.171\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.146\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.198\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.161\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.278\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.104\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.118\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.194\n",
      "Epoch 40: 0.163\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.141\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.157\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.118\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.141\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.124\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.126\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.088\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.135\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.093\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.134\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.120\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.128\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.130\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.125\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.122\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.130\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.187\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.156\n",
      "Epoch 41: 0.141\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.220\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.170\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.137\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.140\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.102\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.097\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.086\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.102\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.099\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.101\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.094\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.097\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.137\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.221\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.117\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.211\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.182\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.101\n",
      "Epoch 42: 0.133\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.065\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.139\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.185\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.123\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.105\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.133\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.207\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.139\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.176\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.187\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.192\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.134\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.121\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.144\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.144\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.099\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.231\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.143\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.146\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.086\n",
      "Epoch 43: 0.149\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.085\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.157\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.204\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.186\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.231\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.094\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.126\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.270\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.219\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.163\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.148\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.154\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.118\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.120\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.138\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.149\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.155\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.253\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.207\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.103\n",
      "Epoch 44: 0.149\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.111\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.147\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.143\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.085\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.123\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.098\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.116\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.098\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.088\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.145\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.102\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.098\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.075\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.100\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.137\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.113\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.100\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.142\n",
      "Epoch 45: 0.119\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.174\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.127\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.085\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.060\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.077\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.075\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.130\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.081\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.125\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.108\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.237\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.159\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.186\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.097\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.104\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.128\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.141\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.209\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.114\n",
      "Epoch 46: 0.121\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.102\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.138\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.082\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.152\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.117\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.081\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.094\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.097\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.118\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.070\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.100\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.191\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.066\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.143\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.167\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.117\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.136\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.118\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.218\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.155\n",
      "Epoch 47: 0.122\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.100\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.086\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.097\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.133\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.114\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.103\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.099\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.121\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.173\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.106\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.126\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.131\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.093\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.091\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.093\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.089\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.174\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.116\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.073\n",
      "Epoch 48: 0.117\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.104\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.171\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.090\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.110\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.147\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.099\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.076\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.126\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.078\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.096\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.063\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.094\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.119\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.127\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.106\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.167\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.106\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.126\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.203\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.182\n",
      "Epoch 49: 0.119\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.100\n",
      "\n",
      "Iteration 10/196\n",
      "Loss: 0.110\n",
      "\n",
      "Iteration 20/196\n",
      "Loss: 0.098\n",
      "\n",
      "Iteration 30/196\n",
      "Loss: 0.107\n",
      "\n",
      "Iteration 40/196\n",
      "Loss: 0.059\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.151\n",
      "\n",
      "Iteration 60/196\n",
      "Loss: 0.089\n",
      "\n",
      "Iteration 70/196\n",
      "Loss: 0.064\n",
      "\n",
      "Iteration 80/196\n",
      "Loss: 0.083\n",
      "\n",
      "Iteration 90/196\n",
      "Loss: 0.083\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.059\n",
      "\n",
      "Iteration 110/196\n",
      "Loss: 0.060\n",
      "\n",
      "Iteration 120/196\n",
      "Loss: 0.127\n",
      "\n",
      "Iteration 130/196\n",
      "Loss: 0.130\n",
      "\n",
      "Iteration 140/196\n",
      "Loss: 0.104\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.124\n",
      "\n",
      "Iteration 160/196\n",
      "Loss: 0.108\n",
      "\n",
      "Iteration 170/196\n",
      "Loss: 0.079\n",
      "\n",
      "Iteration 180/196\n",
      "Loss: 0.074\n",
      "\n",
      "Iteration 190/196\n",
      "Loss: 0.065\n",
      "Epoch 50: 0.097\n"
     ]
    }
   ],
   "source": [
    "from hamiltonianNN.conv_models import ConvHamilNet,ResNet\n",
    "from hamiltonianNN.training import Trainer\n",
    "\n",
    "model = ConvHamilNet(device, img_size, num_filters=64,hidden_dim=128, output_dim=10,\n",
    "                                   augment_dim=0,\n",
    "                                   non_linearity=\"relu\",discret=True,num_layers=100,final_time=5,pool_size=2)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=0.0001)\n",
    "\n",
    "trainer = Trainer(model, optimizer, device,\n",
    "          classification=True,\n",
    "          print_freq=10,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer.train(data_loader, test_input=images[0:64, :,:],test_target=labels[0:64],num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 75.530000 %\n"
     ]
    }
   ],
   "source": [
    "from hamiltonianNN.conv_models import accuracy\n",
    "accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.240000 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0/196\n",
      "Loss: 2.297\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.850\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.607\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.501\n",
      "Epoch 1: 1.729\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.485\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.421\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.430\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.395\n",
      "Epoch 2: 1.415\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.211\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.339\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.231\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.239\n",
      "Epoch 3: 1.295\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.229\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.165\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.259\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.183\n",
      "Epoch 4: 1.228\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.210\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.167\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.112\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.252\n",
      "Epoch 5: 1.171\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.162\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.093\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.047\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.256\n",
      "Epoch 6: 1.114\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.969\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.014\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.075\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.241\n",
      "Epoch 7: 1.077\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.130\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.016\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.012\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.971\n",
      "Epoch 8: 1.044\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.885\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.080\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.018\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.946\n",
      "Epoch 9: 1.024\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.071\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.980\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.023\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.103\n",
      "Epoch 10: 1.010\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.972\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.938\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.986\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 1.031\n",
      "Epoch 11: 0.980\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.041\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.929\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.996\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.982\n",
      "Epoch 12: 0.970\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.021\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 1.075\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.959\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.978\n",
      "Epoch 13: 0.953\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.107\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.873\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.901\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.981\n",
      "Epoch 14: 0.934\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.053\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.925\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.901\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.968\n",
      "Epoch 15: 0.919\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.956\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.923\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 1.030\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.810\n",
      "Epoch 16: 0.902\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.861\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.862\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.884\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.855\n",
      "Epoch 17: 0.895\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.848\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.881\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.921\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.916\n",
      "Epoch 18: 0.888\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.881\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.976\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.761\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.827\n",
      "Epoch 19: 0.861\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.844\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.960\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.875\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.849\n",
      "Epoch 20: 0.871\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.818\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.913\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.704\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.837\n",
      "Epoch 21: 0.853\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 1.009\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.798\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.891\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.822\n",
      "Epoch 22: 0.838\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.780\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.744\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.869\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.823\n",
      "Epoch 23: 0.834\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.833\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.838\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.735\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.792\n",
      "Epoch 24: 0.817\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.771\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.735\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.845\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.822\n",
      "Epoch 25: 0.813\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.799\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.813\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.876\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.834\n",
      "Epoch 26: 0.810\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.757\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.855\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.827\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.840\n",
      "Epoch 27: 0.792\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.789\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.803\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.718\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.708\n",
      "Epoch 28: 0.788\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.871\n",
      "\n",
      "Iteration 50/196\n",
      "Loss: 0.782\n",
      "\n",
      "Iteration 100/196\n",
      "Loss: 0.866\n",
      "\n",
      "Iteration 150/196\n",
      "Loss: 0.847\n",
      "Epoch 29: 0.782\n",
      "\n",
      "Iteration 0/196\n",
      "Loss: 0.768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ConvHamilNet(device, img_size, num_filters=64,hidden_dim=256, output_dim=10,\n",
    "                                   non_linearity=\"relu\",discret=True,num_layers=100,final_time=10,pool_size=2)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=0.01)\n",
    "\n",
    "trainer = Trainer(model, optimizer, device,\n",
    "          classification=True,\n",
    "          print_freq=50,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer.train(data_loader, test_input=images_test[0:1, :,:],test_target=labels_test[0:1],num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 67.190000 %\n"
     ]
    }
   ],
   "source": [
    "from hamiltonianNN.conv_models import accuracy\n",
    "accuracy(test_loader,model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 69.624000 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonianNN.conv_models import accuracy\n",
    "accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(data_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11de0dbe0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainer.histories['test_loss_history'],color='red',label='test loss')\n",
    "plt.plot(trainer.histories['loss_history'],label='Train loss')\n",
    "plt.xlim(0, len(trainer.histories['test_loss_history']) - 1)\n",
    "plt.ylim(0,3)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
