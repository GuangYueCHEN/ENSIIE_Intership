{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import numpy as np\n",
    "import os\n",
    "from anode.conv_models import ConvODENet\n",
    "from anode.discrete_models import ResNet\n",
    "from anode.training import Trainer\n",
    "from experiments.dataloaders import mnist, tiny_imagenet\n",
    "from viz.plots import histories_plt\n",
    "\n",
    "classes = ('0','1', '2', '3', '4',\n",
    "           '5', '6', '7', '8', '9')\n",
    "\n",
    "data_loader, test_loader = mnist(256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 9 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# functions to show an image\n",
    "img_size = (1, 28, 28)\n",
    "output_dim = 10\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4, :,:]))\n",
    "# print labels\n",
    "print(' '.join ('%s' % classes[labels[j]] for j in range(4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Source code of anode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0/235\n",
      "Loss: 2.312\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 10/235\n",
      "Loss: 1.597\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 20/235\n",
      "Loss: 0.533\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 30/235\n",
      "Loss: 0.435\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 40/235\n",
      "Loss: 0.477\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 50/235\n",
      "Loss: 0.416\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 60/235\n",
      "Loss: 0.364\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 70/235\n",
      "Loss: 0.306\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 80/235\n",
      "Loss: 0.292\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 90/235\n",
      "Loss: 0.384\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 100/235\n",
      "Loss: 0.350\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 110/235\n",
      "Loss: 0.353\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 120/235\n",
      "Loss: 0.287\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 130/235\n",
      "Loss: 0.320\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 140/235\n",
      "Loss: 0.243\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 150/235\n",
      "Loss: 0.339\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 160/235\n",
      "Loss: 0.292\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 170/235\n",
      "Loss: 0.261\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 180/235\n",
      "Loss: 0.165\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 190/235\n",
      "Loss: 0.283\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 200/235\n",
      "Loss: 0.325\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 210/235\n",
      "Loss: 0.278\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 220/235\n",
      "Loss: 0.188\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 230/235\n",
      "Loss: 0.237\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "Epoch 1: 0.431\n",
      "\n",
      "Iteration 0/235\n",
      "Loss: 0.305\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 10/235\n",
      "Loss: 0.218\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 20/235\n",
      "Loss: 0.308\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 30/235\n",
      "Loss: 0.230\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 40/235\n",
      "Loss: 0.304\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 50/235\n",
      "Loss: 0.145\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 60/235\n",
      "Loss: 0.254\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 70/235\n",
      "Loss: 0.353\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 80/235\n",
      "Loss: 0.233\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 90/235\n",
      "Loss: 0.163\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 100/235\n",
      "Loss: 0.256\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 110/235\n",
      "Loss: 0.175\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 120/235\n",
      "Loss: 0.209\n",
      "NFE: 20\n",
      "BNFE: 45\n",
      "Total NFE: 65\n",
      "\n",
      "Iteration 130/235\n",
      "Loss: 0.215\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 140/235\n",
      "Loss: 0.241\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 150/235\n",
      "Loss: 0.173\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 160/235\n",
      "Loss: 0.210\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 170/235\n",
      "Loss: 0.183\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 180/235\n",
      "Loss: 0.191\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 190/235\n",
      "Loss: 0.236\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 200/235\n",
      "Loss: 0.221\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 210/235\n",
      "Loss: 0.121\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 220/235\n",
      "Loss: 0.198\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 230/235\n",
      "Loss: 0.184\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "Epoch 2: 0.213\n",
      "\n",
      "Iteration 0/235\n",
      "Loss: 0.292\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 10/235\n",
      "Loss: 0.172\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 20/235\n",
      "Loss: 0.204\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 30/235\n",
      "Loss: 0.173\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 40/235\n",
      "Loss: 0.135\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 50/235\n",
      "Loss: 0.270\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 60/235\n",
      "Loss: 0.146\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 70/235\n",
      "Loss: 0.137\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 80/235\n",
      "Loss: 0.162\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 90/235\n",
      "Loss: 0.120\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 100/235\n",
      "Loss: 0.222\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 110/235\n",
      "Loss: 0.132\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 120/235\n",
      "Loss: 0.146\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 130/235\n",
      "Loss: 0.235\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 140/235\n",
      "Loss: 0.136\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 150/235\n",
      "Loss: 0.153\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 160/235\n",
      "Loss: 0.124\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 170/235\n",
      "Loss: 0.181\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 180/235\n",
      "Loss: 0.119\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 190/235\n",
      "Loss: 0.232\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 200/235\n",
      "Loss: 0.141\n",
      "NFE: 20\n",
      "BNFE: 39\n",
      "Total NFE: 59\n",
      "\n",
      "Iteration 210/235\n",
      "Loss: 0.080\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 220/235\n",
      "Loss: 0.201\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 230/235\n",
      "Loss: 0.129\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "Epoch 3: 0.147\n",
      "\n",
      "Iteration 0/235\n",
      "Loss: 0.098\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 10/235\n",
      "Loss: 0.142\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 20/235\n",
      "Loss: 0.141\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 30/235\n",
      "Loss: 0.131\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 40/235\n",
      "Loss: 0.084\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 50/235\n",
      "Loss: 0.164\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 60/235\n",
      "Loss: 0.121\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 70/235\n",
      "Loss: 0.135\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 80/235\n",
      "Loss: 0.094\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 90/235\n",
      "Loss: 0.078\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 100/235\n",
      "Loss: 0.070\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 110/235\n",
      "Loss: 0.137\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 120/235\n",
      "Loss: 0.122\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 130/235\n",
      "Loss: 0.065\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 140/235\n",
      "Loss: 0.095\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 150/235\n",
      "Loss: 0.142\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 160/235\n",
      "Loss: 0.053\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 170/235\n",
      "Loss: 0.129\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 180/235\n",
      "Loss: 0.089\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 190/235\n",
      "Loss: 0.079\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 200/235\n",
      "Loss: 0.054\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 210/235\n",
      "Loss: 0.077\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 220/235\n",
      "Loss: 0.105\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 230/235\n",
      "Loss: 0.188\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "Epoch 4: 0.104\n",
      "\n",
      "Iteration 0/235\n",
      "Loss: 0.088\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 10/235\n",
      "Loss: 0.075\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 20/235\n",
      "Loss: 0.074\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 30/235\n",
      "Loss: 0.098\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 40/235\n",
      "Loss: 0.059\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 50/235\n",
      "Loss: 0.060\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 60/235\n",
      "Loss: 0.074\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 70/235\n",
      "Loss: 0.096\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 80/235\n",
      "Loss: 0.095\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 90/235\n",
      "Loss: 0.079\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 100/235\n",
      "Loss: 0.044\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 110/235\n",
      "Loss: 0.057\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 120/235\n",
      "Loss: 0.038\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 130/235\n",
      "Loss: 0.103\n",
      "NFE: 20\n",
      "BNFE: 33\n",
      "Total NFE: 53\n",
      "\n",
      "Iteration 140/235\n",
      "Loss: 0.080\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 150/235\n",
      "Loss: 0.086\n",
      "NFE: 20\n",
      "BNFE: 21\n",
      "Total NFE: 41\n",
      "\n",
      "Iteration 160/235\n",
      "Loss: 0.056\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 170/235\n",
      "Loss: 0.080\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 180/235\n",
      "Loss: 0.078\n",
      "NFE: 20\n",
      "BNFE: 45\n",
      "Total NFE: 65\n",
      "\n",
      "Iteration 190/235\n",
      "Loss: 0.064\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 200/235\n",
      "Loss: 0.089\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 210/235\n",
      "Loss: 0.055\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 220/235\n",
      "Loss: 0.093\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "\n",
      "Iteration 230/235\n",
      "Loss: 0.083\n",
      "NFE: 20\n",
      "BNFE: 27\n",
      "Total NFE: 47\n",
      "Epoch 5: 0.079\n"
     ]
    }
   ],
   "source": [
    "model = ConvODENet(device, img_size, num_filters=64, output_dim=10,\n",
    "                                   augment_dim=5,\n",
    "                                   time_dependent=True,\n",
    "                                   non_linearity=\"relu\",\n",
    "                                   adjoint=True)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=0.0)\n",
    "\n",
    "trainer = Trainer(model, optimizer, device,\n",
    "          classification=True,\n",
    "          print_freq=10,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer.train(data_loader, test_input=images[0:64, :,:],test_target=labels[0:64],num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./model')==False:\n",
    "    os.mkdir('./model')\n",
    "torch.save(model, './model/anode_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvODENet(\n",
       "  (odeblock): ODEBlock(\n",
       "    (odefunc): ConvODEFunc(\n",
       "      (conv1): Conv2dTime(7, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2dTime(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2dTime(65, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (non_linearity): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer): Linear(in_features=4704, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model/anode_model')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonianNN.conv_models import ConvHamilNet,ResNet\n",
    "from hamiltonianNN.training import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0/235\n",
      "Loss: 2.308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d0506de29c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m          )\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WTF/Plus/DeepLearning/intership/ENSIIE_Intership/Hamilton_Network/hamiltonianNN/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, test_input, test_target, num_epochs, Rrate, R)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mRrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WTF/Plus/DeepLearning/intership/ENSIIE_Intership/Hamilton_Network/hamiltonianNN/training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader, test_input, test_target, Rrate, R)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRrate\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mR_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvHamilNet(device, img_size, num_filters=64,hidden_dim=128, output_dim=10,\n",
    "                                   augment_dim=0,\n",
    "                                   non_linearity=\"relu\",discret=True,num_layers=100,final_time=5)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=0.0)\n",
    "\n",
    "trainer = Trainer(model, optimizer, device,\n",
    "          classification=True,\n",
    "          print_freq=10,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer.train(data_loader, test_input=images[0:2, :,:],test_target=labels[0:2],num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pingguo/WTF/Plus/DeepLearning/intership/ENSIIE_Intership/Hamilton_Network/torchdiffeq/_impl/misc.py:81: UserWarning: Leapfrog: Unexpected arguments {'max_num_steps': 1000}\n",
      "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0/235\n",
      "Loss: 2.321\n",
      "NFE: 2\n",
      "BNFE: 0\n",
      "Total NFE: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f5f67dc0233c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m          )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WTF/Plus/DeepLearning/intership/ENSIIE_Intership/Hamilton_Network/hamiltonianNN/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, test_input, test_target, num_epochs, Rrate, R)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_target\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mRrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WTF/Plus/DeepLearning/intership/ENSIIE_Intership/Hamilton_Network/hamiltonianNN/training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader, test_input, test_target, Rrate, R)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRrate\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mR_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = ConvHamilNet(device, img_size, num_filters=64,hidden_dim=128, output_dim=10,augment_dim=0,\n",
    "                                   non_linearity=\"relu\",adjoint=True,level=7, method='leapfrog', discret=False)\n",
    "\n",
    "model2.to(device)\n",
    "\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(),lr=1e-3,weight_decay=0.0)\n",
    "\n",
    "trainer2 = Trainer(model2, optimizer2, device,\n",
    "          classification=True,\n",
    "          print_freq=10,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer2.train(data_loader, test_input=images[0:2, :,:],test_target=labels[0:2],num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = ResNet(device, img_size, num_filters=64, output_dim=10,num_layers=6,\n",
    "                                   non_linearity=\"relu\")\n",
    "res_model.to(device)\n",
    "\n",
    "res_optimizer = torch.optim.Adam(res_model.parameters(),lr=1e-3,weight_decay=0.0)\n",
    "\n",
    "trainer = Trainer(res_model, res_optimizer, device,\n",
    "          classification=True,\n",
    "          print_freq=10,\n",
    "          record_freq=10,\n",
    "          verbose=True,\n",
    "         )\n",
    "trainer.train(data_loader, test_input=images[0:64, :,:],test_target=labels[0:64],num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model2, './model/hamil_discret_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.700000 %\n",
      "Accuracy of the network on the 10000 test images: 98.270000 %\n",
      "Accuracy of the network on the 10000 test images: 98.870000 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = torch.load('./model/hamil_discret_model')  \n",
    "accuracy(test_loader,model)\n",
    "\n",
    "model = torch.load('./model/hamil_model')  \n",
    "accuracy(test_loader,model)\n",
    "\n",
    "model = torch.load('./model/resnet_model')  \n",
    "accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total': 146207, 'Trainable': 146207}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model/hamil_model') \n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamilnet.hamil_blocks.0.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.0.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.0.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.1.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.1.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.1.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.2.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.2.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.2.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.3.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.3.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.3.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.4.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.4.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.4.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.5.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.5.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.5.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.6.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.6.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.6.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.7.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.7.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.7.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.8.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.8.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.8.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.9.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.9.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.9.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.10.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.10.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.10.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.11.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.11.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.11.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.12.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.12.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.12.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.13.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.13.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.13.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.14.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.14.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.14.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.15.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.15.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.15.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.16.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.16.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.16.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.17.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.17.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.17.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.18.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.18.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.18.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.19.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.19.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.19.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.20.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.20.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.20.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.21.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.21.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.21.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.22.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.22.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.22.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.23.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.23.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.23.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.24.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.24.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.24.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.25.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.25.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.25.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.26.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.26.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.26.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.27.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.27.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.27.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.28.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.28.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.28.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.29.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.29.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.29.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.30.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.30.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.30.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.31.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.31.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.31.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.32.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.32.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.32.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.33.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.33.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.33.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.34.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.34.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.34.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.35.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.35.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.35.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.36.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.36.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.36.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.37.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.37.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.37.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.38.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.38.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.38.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.39.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.39.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.39.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.40.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.40.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.40.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.41.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.41.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.41.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.42.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.42.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.42.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.43.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.43.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.43.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.44.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.44.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.44.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.45.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.45.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.45.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.46.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.46.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.46.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.47.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.47.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.47.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.48.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.48.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.48.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.49.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.49.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.49.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.50.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.50.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.50.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.51.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.51.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.51.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.52.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.52.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.52.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.53.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.53.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.53.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.54.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.54.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.54.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.55.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.55.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.55.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.56.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.56.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.56.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.57.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.57.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.57.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.58.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.58.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.58.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.59.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.59.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.59.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.60.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.60.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.60.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.61.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.61.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.61.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.62.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.62.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.62.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.63.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.63.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.63.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.64.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.64.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.64.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.65.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.65.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.65.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.66.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.66.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.66.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.67.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.67.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.67.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.68.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.68.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.68.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.69.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.69.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.69.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.70.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.70.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.70.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.71.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.71.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.71.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.72.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.72.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.72.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.73.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.73.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.73.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.74.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.74.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.74.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.75.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.75.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.75.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.76.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.76.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.76.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.77.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.77.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.77.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.78.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.78.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.78.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.79.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.79.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.79.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.80.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.80.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.80.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.81.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.81.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.81.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.82.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.82.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.82.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.83.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.83.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.83.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.84.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.84.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.84.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.85.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.85.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.85.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.86.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.86.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.86.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.87.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.87.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.87.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.88.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.88.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.88.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.89.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.89.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.89.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.90.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.90.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.90.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.91.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.91.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.91.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.92.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.92.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.92.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.93.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.93.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.93.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.94.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.94.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.94.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.95.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.95.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.95.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.96.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.96.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.96.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.97.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.97.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.97.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.98.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.98.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.98.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.hamil_blocks.99.mlp.0.weight : torch.Size([128, 64])\n",
      "hamilnet.hamil_blocks.99.mlp.0.bias : torch.Size([128])\n",
      "hamilnet.hamil_blocks.99.vts.weight : torch.Size([64, 64])\n",
      "hamilnet.linear_layer.weight : torch.Size([10, 128])\n",
      "hamilnet.linear_layer.bias : torch.Size([10])\n",
      "net.0.weight : torch.Size([64, 1, 3, 3])\n",
      "net.0.bias : torch.Size([64])\n",
      "net.1.weight : torch.Size([64])\n",
      "net.1.bias : torch.Size([64])\n",
      "net.3.weight : torch.Size([64, 64, 4, 4])\n",
      "net.3.bias : torch.Size([64])\n",
      "net.4.weight : torch.Size([64])\n",
      "net.4.bias : torch.Size([64])\n",
      "net.6.weight : torch.Size([64, 64, 4, 4])\n",
      "net.6.bias : torch.Size([64])\n",
      "net.7.weight : torch.Size([64])\n",
      "net.7.bias : torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "parm={}\n",
    "for name,parameters in model.named_parameters():\n",
    "    print(name,':',parameters.size())\n",
    "#parm[name]=parameters.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total': 1375114, 'Trainable': 1375114}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model/hamil_discret_model')  \n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total': 602506, 'Trainable': 602506}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model/resnet_model') \n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'hamiltonianNN.models.HODENet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'hamiltonianNN.models.ODEFuncH3' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvHamilNet(\n",
       "  (hamilnet): HODENet(\n",
       "    (odeblock): HODEBlock(\n",
       "      (odefunc): ODEFuncH3(\n",
       "        (fc1): Linear(in_features=65, out_features=128, bias=True)\n",
       "        (fc2): Linear(in_features=65, out_features=65, bias=False)\n",
       "        (non_linearity1): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=130, out_features=10, bias=True)\n",
       "  )\n",
       "  (odeblock): HODEBlock(\n",
       "    (odefunc): ODEFuncH3(\n",
       "      (fc1): Linear(in_features=65, out_features=128, bias=True)\n",
       "      (fc2): Linear(in_features=65, out_features=65, bias=False)\n",
       "      (non_linearity1): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (10): Flatten()\n",
       "    (11): HODENet(\n",
       "      (odeblock): HODEBlock(\n",
       "        (odefunc): ODEFuncH3(\n",
       "          (fc1): Linear(in_features=65, out_features=128, bias=True)\n",
       "          (fc2): Linear(in_features=65, out_features=65, bias=False)\n",
       "          (non_linearity1): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=130, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from hamiltonianNN.conv_models import ConvHamilNet,ResNet,Flatten,ResBlock\n",
    "from hamiltonianNN.training import Trainer\n",
    "model = torch.load('./model/hamil_model')\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
